#!/usr/bin/env python3
"""
çµ±è¨ˆInterPro taxonomy JSONæ–‡ä»¶ä¸­çš„ç¯€é»æ•¸é‡
"""

import json
import sys
import os
from pathlib import Path

def count_taxonomy_nodes(json_file_path):
    """
    çµ±è¨ˆJSONæ–‡ä»¶ä¸­çš„taxonomyç¯€é»æ•¸é‡
    
    Args:
        json_file_path (str): JSONæ–‡ä»¶è·¯å¾‘
        
    Returns:
        dict: åŒ…å«çµ±è¨ˆä¿¡æ¯çš„å­—å…¸
    """
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ç²å–åŸºæœ¬çµ±è¨ˆä¿¡æ¯
        total_count = data.get('count', 0)
        results = data.get('results', [])
        actual_nodes = len(results)
        
        # çµ±è¨ˆæœ‰childrençš„ç¯€é»æ•¸é‡
        nodes_with_children = 0
        nodes_without_children = 0
        
        for node in results:
            metadata = node.get('metadata', {})
            children = metadata.get('children', [])
            
            if children:
                nodes_with_children += 1
            else:
                nodes_without_children += 1
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†é 
        has_next_page = data.get('next') is not None
        has_previous_page = data.get('previous') is not None
        
        return {
            'file_path': json_file_path,
            'total_count_from_api': total_count,
            'actual_nodes_in_file': actual_nodes,
            'nodes_with_children': nodes_with_children,
            'nodes_without_children': nodes_without_children,
            'has_next_page': has_next_page,
            'has_previous_page': has_previous_page,
            'is_complete_dataset': not has_next_page and not has_previous_page
        }
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æéŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ è™•ç†æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def print_statistics(stats):
    """
    æ‰“å°çµ±è¨ˆçµæœ
    
    Args:
        stats (dict): çµ±è¨ˆä¿¡æ¯å­—å…¸
    """
    if not stats:
        return
    
    print("=" * 60)
    print(f"ğŸ“Š Taxonomyç¯€é»çµ±è¨ˆçµæœ")
    print("=" * 60)
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾‘: {stats['file_path']}")
    print(f"ğŸ”¢ APIè¿”å›çš„ç¸½æ•¸é‡: {stats['total_count_from_api']:,}")
    print(f"ğŸ“‹ æ–‡ä»¶ä¸­å¯¦éš›ç¯€é»æ•¸: {stats['actual_nodes_in_file']:,}")
    print(f"ğŸŒ³ æœ‰å­ç¯€é»çš„ç¯€é»æ•¸: {stats['nodes_with_children']:,}")
    print(f"ğŸƒ è‘‰å­ç¯€é»æ•¸: {stats['nodes_without_children']:,}")
    print(f"ğŸ“„ æœ‰ä¸‹ä¸€é : {'æ˜¯' if stats['has_next_page'] else 'å¦'}")
    print(f"ğŸ“„ æœ‰ä¸Šä¸€é : {'æ˜¯' if stats['has_previous_page'] else 'å¦'}")
    print(f"âœ… å®Œæ•´æ•¸æ“šé›†: {'æ˜¯' if stats['is_complete_dataset'] else 'å¦'}")
    
    if not stats['is_complete_dataset']:
        print(f"âš ï¸  æ³¨æ„: é€™ä¸æ˜¯å®Œæ•´çš„æ•¸æ“šé›†ï¼Œç¸½å…±æœ‰ {stats['total_count_from_api']:,} å€‹ç¯€é»")
        print(f"   ç•¶å‰æ–‡ä»¶åªåŒ…å« {stats['actual_nodes_in_file']:,} å€‹ç¯€é»")

def process_directory(directory_path):
    """
    æ‰¹é‡è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶

    Args:
        directory_path (str): ç›®éŒ„è·¯å¾‘
    """
    json_files = list(Path(directory_path).glob("*_taxonomy.json"))

    if not json_files:
        print(f"âŒ åœ¨ç›®éŒ„ {directory_path} ä¸­æ²’æœ‰æ‰¾åˆ° *_taxonomy.json æ–‡ä»¶")
        return

    print(f"ğŸ” æ‰¾åˆ° {len(json_files)} å€‹taxonomy JSONæ–‡ä»¶")
    print("=" * 80)

    total_api_count = 0
    total_actual_nodes = 0
    complete_files = 0
    incomplete_files = 0

    for json_file in sorted(json_files):
        stats = count_taxonomy_nodes(str(json_file))
        if stats:
            ipr_id = json_file.stem.replace('_taxonomy', '')
            print(f"ğŸ“„ {ipr_id}: {stats['actual_nodes_in_file']:,} ç¯€é» "
                  f"(ç¸½å…± {stats['total_count_from_api']:,})")

            total_api_count += stats['total_count_from_api']
            total_actual_nodes += stats['actual_nodes_in_file']

            if stats['is_complete_dataset']:
                complete_files += 1
            else:
                incomplete_files += 1
        else:
            print(f"âŒ è™•ç†å¤±æ•—: {json_file}")

    print("=" * 80)
    print(f"ğŸ“Š ç¸½çµ:")
    print(f"   è™•ç†çš„æ–‡ä»¶æ•¸: {len(json_files)}")
    print(f"   å®Œæ•´æ•¸æ“šé›†: {complete_files}")
    print(f"   ä¸å®Œæ•´æ•¸æ“šé›†: {incomplete_files}")
    print(f"   APIç¸½ç¯€é»æ•¸: {total_api_count:,}")
    print(f"   å¯¦éš›ä¸‹è¼‰ç¯€é»æ•¸: {total_actual_nodes:,}")

def main():
    """
    ä¸»å‡½æ•¸
    """
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  å–®å€‹æ–‡ä»¶: python count_taxonomy_nodes.py <json_file_path>")
        print("  æ‰¹é‡è™•ç†: python count_taxonomy_nodes.py <directory_path>")
        print("ä¾‹å¦‚:")
        print("  python count_taxonomy_nodes.py database/interpro_type_domain/IPR000008_taxonomy.json")
        print("  python count_taxonomy_nodes.py database/interpro_type_domain/")
        sys.exit(1)

    input_path = sys.argv[1]

    # æª¢æŸ¥è¼¸å…¥æ˜¯æ–‡ä»¶é‚„æ˜¯ç›®éŒ„
    if os.path.isfile(input_path):
        # è™•ç†å–®å€‹æ–‡ä»¶
        stats = count_taxonomy_nodes(input_path)
        if stats:
            print_statistics(stats)
        else:
            print("âŒ çµ±è¨ˆå¤±æ•—")
            sys.exit(1)
    elif os.path.isdir(input_path):
        # æ‰¹é‡è™•ç†ç›®éŒ„
        process_directory(input_path)
    else:
        print(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)

if __name__ == "__main__":
    main()
